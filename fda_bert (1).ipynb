{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OC4myO8MFIB",
        "outputId": "33e8dece-8229-4e9d-bda1-2e5292f62d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test GPU\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU detected')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqzb5aetsUA_",
        "outputId": "d8b6383b-6195-467a-a257-c9db7ae9f82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4GKhCyzPAke",
        "outputId": "6884be60-4d36-4b53-942e-32236b3fe94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Y9RiHftaMbzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Artificial Intelligence and Machine Learning (AIML)-Enabled Medical Devices  FDA (1).csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "eBKhmoS3QIWI",
        "outputId": "ca6f660d-98ae-4132-bb68-60e53d6a8266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices | FDA  ...            Unnamed: 5\n",
              "0                             Date of Final Decision                                  ...  Primary Product Code\n",
              "1                                         07/29/2022                                  ...                   KGI\n",
              "2                                         07/29/2022                                  ...                   JAK\n",
              "3                                         07/28/2022                                  ...                   QIH\n",
              "4                                         07/28/2022                                  ...                   LNH\n",
              "\n",
              "[5 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46e46c28-010b-4f17-8406-0290eeb601bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices | FDA</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Date of Final Decision</td>\n",
              "      <td>Submission Number</td>\n",
              "      <td>Device</td>\n",
              "      <td>Company</td>\n",
              "      <td>Panel (Lead)</td>\n",
              "      <td>Primary Product Code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07/29/2022</td>\n",
              "      <td>K213760</td>\n",
              "      <td>ABMD Software</td>\n",
              "      <td>HeartLung Corporation</td>\n",
              "      <td>Radiology</td>\n",
              "      <td>KGI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07/29/2022</td>\n",
              "      <td>K220961</td>\n",
              "      <td>Deep Learning Image Reconstruction</td>\n",
              "      <td>GE Healthcare Japan Corporation</td>\n",
              "      <td>Radiology</td>\n",
              "      <td>JAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07/28/2022</td>\n",
              "      <td>K213998</td>\n",
              "      <td>cvi42 Auto Imaging Software Application</td>\n",
              "      <td>Circle Cardiovascular Imaging Inc</td>\n",
              "      <td>Radiology</td>\n",
              "      <td>QIH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07/28/2022</td>\n",
              "      <td>K221923</td>\n",
              "      <td>Swoop Portable MR Imaging System</td>\n",
              "      <td>Hyperfine, Inc.</td>\n",
              "      <td>Radiology</td>\n",
              "      <td>LNH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46e46c28-010b-4f17-8406-0290eeb601bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46e46c28-010b-4f17-8406-0290eeb601bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46e46c28-010b-4f17-8406-0290eeb601bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-512a3660-203f-4690-bb92-8c2ea925a437\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-512a3660-203f-4690-bb92-8c2ea925a437')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-512a3660-203f-4690-bb92-8c2ea925a437 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 522,\n  \"fields\": [\n    {\n      \"column\": \"Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices | FDA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"11/08/1995\",\n          \"06/10/2021\",\n          \"03/29/2019\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 522,\n        \"samples\": [\n          \"K120771\",\n          \"K190013\",\n          \"K220624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 460,\n        \"samples\": [\n          \"Vivid E80/ Vivid E90/ Vivid E95\",\n          \"CINA CHEST\",\n          \"ClariCT AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 343,\n        \"samples\": [\n          \"Pathwork Diagnostics, Inc.\",\n          \"Therapixel\",\n          \"RADLogics, Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Panel (Lead)\",\n          \"Radiology\",\n          \"Obstetrics And Gynecology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 5\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"QEA\",\n          \"JAA\",\n          \"MUD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "list(uploaded.keys())"
      ],
      "metadata": {
        "id": "xJKXF28JaWUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "c82d0468-c826-4d4e-df42-b664fa0f98e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5f55ef14-e838-4496-89b7-e9e53838a37e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5f55ef14-e838-4496-89b7-e9e53838a37e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving system_design_qa.json to system_design_qa.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system_design_qa.json']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": list(uploaded.keys())[0]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "28af2272bf9344f086dcb50b62e73267",
            "8750a3364a4f492493e611b256b51e0a",
            "312aa2b1aaab45248630c61cb92c9192",
            "4ebabbdb83a9488e95a51ed08a35fae4",
            "f91c923571a04c618142bf1c2a5e70a5",
            "67c402693683459b9ff3e482e791fdc7",
            "6f4cefea324f4101b88e43796c1d8608",
            "8323af27acc14f8d93037161b0738ef9",
            "877fe1d6ad6b4abeaee9f0fd0762a2ef",
            "ed1ffb36fada4083991431573c4603aa",
            "33ebbf74366a45c7ba42a0f1b3b4646e"
          ]
        },
        "id": "wo6JHOQ4LgSG",
        "outputId": "5aa479c4-a334-4861-9542-b2b43ba48276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28af2272bf9344f086dcb50b62e73267"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "697533510dba4b7ea8395f34f9707084",
            "d3bdc9fdb37346719f1b5f6935b6aaf5",
            "f83dbc3e0f9445d4bcce85ca06c957bd",
            "a9f9b7f679754809bfdd40ce16579163",
            "147cc918ddbc46998aadc9da5e0313b1",
            "fcdf6278619f4d329a76f7d860d3ac9b",
            "ce8feab34a36469e8e121102022cda3d",
            "f3a3385a5d8a43a1ad5c9c7b38d8b1bd",
            "77f072d061a9459c8535f4236f5b9581",
            "33caeda6f3694f90b5c25c91ed529b9c",
            "6d4dc098f73f4bffa2eb99e21d2d973f",
            "7ebaaca834e8471bbee55795abad55bf",
            "1e9f81ede6784ca7a6ac03a3db872fad",
            "11eb665985684c65bf15838b23c46d57",
            "fec96bc9fce34790a62be0f503678592",
            "2a19a7039e984110be1a6ef63ce78c6f",
            "f331a06ae3e148e7b403adf3fca46b2b",
            "c0dcfad3b0104912811fd169d7f3ce15",
            "ef15ee5da52c4cc18fc01891d99d82c4",
            "9472077106ce4db797c34707f8fa1cde",
            "236178a3a7bc48d098d9ac4a4f595fd6",
            "06addf1d0bca4f97b1d96e77e5868421",
            "665281382c4e4685b05a626813ef4de6",
            "661e4855cb5c4e9ca29726c39960017e",
            "7dd5af2b9d104fe9aa60c58f03aa29ac",
            "f41dfd5e47414b7d8827218ad584d05d",
            "e100d44725424b7081c82afd9506383e",
            "8a8eea20bbc14f1bacfbcf8fe09c0e81",
            "a4813e5cfa994913ad18187cfb9debb7",
            "9922ba1671a647e883815eaa7eb778a7",
            "8649e6b0636c4610b28f3e8447ff811c",
            "bf9c2a52b9874947b38f7a907c074d63",
            "b74b83ff8bc24259ae2ca3444e356c18",
            "4f8d757c361443119b726ffab57750c3",
            "5afdb545837848a3b0cd2fa0d9d32026",
            "c6eb029f4e85470d809c87e9df349316",
            "45226fc83aad4abb88fa5fbed81ba0de",
            "e7acd65d68c040348c3ac3dff4bb586e",
            "a00a764546bc4aa08b5a362472936c7f",
            "e5673b1097d9454186d5251661c3ffba",
            "7459ac0e18814ab5831ac9949b4250c0",
            "5033d3f7727c4dfb92ba09f82193601e",
            "df864b9af70d4e1dbfaf7159ba6a9010",
            "c952690dd61e4a4c8edc1941d347ad48",
            "41eb9da048cb4ad5bdfcd787a1ffd2ef",
            "41d4d9f67ab04b4c8a32c1c9994e9b4b",
            "938bac753ed546beb96630fd2fb13fa8",
            "515e51079a6543739a5d525e0f41cb23",
            "c2a5658c34554a3188ca58a368c1c93c",
            "6497c0478aa44c03804922257da8041d",
            "8e88e4071ad14d92b42014cd31f03ea8",
            "79d298f400ae4f578d5b0db1328d5134",
            "0047ac0fb13d4326a2ff0cf9e3fee1da",
            "df594364defc4e289ac912d2ba85583f",
            "bc8da17e1c0f42a188d19fe3b8cb7a0f",
            "42ecf35eac4845fa8733ffe2de56f35a",
            "e8de4cf8b00f4585bc9f277ebe033033",
            "dcf21d57b92040a39b63f76c77746b8e",
            "d5ab6cc815b14082b90065be7e458ee0",
            "4356d541d7b4410e923991137f21e1ff",
            "c7833e31257f48f08dd645e073e20c80",
            "2639a69a05fe468c9e2b3f708791e465",
            "0c030265d0b14844a6d82d8c18b181a0",
            "93077e993ab243b4988768f1e441d4ac",
            "04b2c267b76a4264889eabfb087a28be",
            "75f1af6389a94eca8d342bd43124b500"
          ]
        },
        "id": "h9szwgNoOXlC",
        "outputId": "c396e5c6-43cf-4fb6-8cf4-a8becfe32b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "697533510dba4b7ea8395f34f9707084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ebaaca834e8471bbee55795abad55bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "665281382c4e4685b05a626813ef4de6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f8d757c361443119b726ffab57750c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41eb9da048cb4ad5bdfcd787a1ffd2ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42ecf35eac4845fa8733ffe2de56f35a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "from typing import List, Dict, Any"
      ],
      "metadata": {
        "id": "JsyQbSiaPGsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load + flatten utility (handles nested SQuAD automatically)\n",
        "def load_and_flatten(files: List[str]) -> Dataset:\n",
        "  rows = []\n",
        "  for fp in files:\n",
        "    with open(fp, \"r\") as f:\n",
        "      data = json.load(f)\n",
        "\n",
        "    if isinstance(data, dict) and \"data\" in data:\n",
        "      for item in data[\"data\"]:\n",
        "        title = item.get(\"title\", \"\")\n",
        "        for para in item.get(\"paragraphs\", []):\n",
        "          context = para.get(\"context\", \"\")\n",
        "          for qa in para.get(\"qas\", []):\n",
        "            q = qa.get(\"question\", \"\")\n",
        "            qa_id = qa.get(\"id\", \"\")\n",
        "            ans = qa.get(\"answers\", [])\n",
        "\n",
        "            if isinstance(ans, list):\n",
        "              texts = [a[\"text\"] for a in ans]\n",
        "              starts = [a[\"answer_start\"] for a in ans]\n",
        "              answers = {\"text\": texts, \"answer_start\": starts}\n",
        "            else:\n",
        "              answers = {\n",
        "                  \"text\": ans.get(\"text\", []),\n",
        "                  \"answer_start\": ans.get(\"answer_start\", [])\n",
        "              }\n",
        "            rows.append({\n",
        "                \"id\": qa_id,\n",
        "                \"title\": title,\n",
        "                \"context\": context,\n",
        "                \"question\": q,\n",
        "                \"answers\": answers\n",
        "            })\n",
        "    elif isinstance(data, list):\n",
        "      for r in data:\n",
        "        answers = r.get(\"answers\", {})\n",
        "        if isinstance(answers, list):\n",
        "          answers = {\n",
        "              \"text\": [a[\"text\"] for a in answers],\n",
        "              \"answer_start\": [a[\"answer_start\"] for a in answers]\n",
        "          }\n",
        "        rows.append({\n",
        "            \"id\": r.get(\"id\", \"\"),\n",
        "            \"title\": r.get(\"title\", \"\"),\n",
        "            \"context\": r.get(\"context\"),\n",
        "            \"question\": r.get(\"question\"),\n",
        "            \"answers\": answers\n",
        "        })\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported data format in {fp}\")\n",
        "  return Dataset.from_list(rows)\n",
        "files = list(uploaded.keys())\n",
        "dataset = load_and_flatten(files)\n",
        "print(dataset)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW462Kk0c7C_",
        "outputId": "a988ac56-0064-456b-f3b9-f28b1a83226e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "    num_rows: 6\n",
            "})\n",
            "{'id': 'rivanna_q1', 'title': 'Rivanna_Accuro', 'context': 'Hardware: Accuro, Consumables, True-View Trolley, Accuro XV, ultrasound guidance platform, Accuro® 3S diagnostic ultrasound system, Trolley, cords, adapters, Locator kits, Locator needle guides, imaging-based medical technology. Software Components: automated landmark identification, AI-enabled image guidance, CADe/x AI module, AI-driven imaging software, True-View, Upgrade, proprietary technology solutions. AI Models: AI-enabled image guidance, CADe/x AI module, AI-driven imaging software. Data Pipelines: No cloud subscription required, crucial data, midline and intervertebral space detection, imaging-based solution, aggregate usage data, collect information from third-party sources. User Interface: Pinpoint key neuraxial targets, integrated clinician support, True-View, Website(s), online contact form, social network accounts. Integration with other systems: government, industry, clinical settings, third-party vendors, web browsers, regulatory bodies, public databases.', 'question': 'What hardware components are used in the system?', 'answers': {'answer_start': [10], 'text': ['Accuro, Consumables, True-View Trolley, Accuro XV, ultrasound guidance platform, Accuro® 3S diagnostic ultrasound system, Trolley, cords, adapters, Locator kits, Locator needle guides, imaging-based medical technology']}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train/ Validation split (90/10 by default)\n",
        "ds = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "raw = DatasetDict({\"train\": ds[\"train\"], \"validation\": ds[\"test\"]})\n",
        "raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjjitbvXomvx",
        "outputId": "44e61e1c-e255-4703-b905-a82582cb821c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 5\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 1\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize in SQuaD-style\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
        "\n",
        "def preprocess_batch(batch):\n",
        "    questions = [q.lstrip() for q in batch[\"question\"]]\n",
        "    contexts = batch[\"context\"]\n",
        "    answers = batch[\"answers\"]\n",
        "\n",
        "    tokenized_inputs = tokenizer(\n",
        "        questions,\n",
        "        contexts,\n",
        "        truncation=\"only_second\", # Truncate only the context\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "        return_offsets_mapping=True, # Needed to map token positions to character positions\n",
        "    )\n",
        "\n",
        "    input_ids = tokenized_inputs[\"input_ids\"]\n",
        "    attention_mask = tokenized_inputs[\"attention_mask\"]\n",
        "    offset_mapping = tokenized_inputs[\"offset_mapping\"]\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        input_id = input_ids[i]\n",
        "        cls_index = input_id.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        sequence_ids = tokenized_inputs.sequence_ids(i)\n",
        "        context_start = sequence_ids.index(1)\n",
        "        context_end = len(sequence_ids) - 1 - list(reversed(sequence_ids)).index(1)\n",
        "\n",
        "        # If there's no answer, label with the CLS index\n",
        "        if not answers[i][\"answer_start\"]:\n",
        "            start_positions.append(cls_index)\n",
        "            end_positions.append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text\n",
        "            start_char = answers[i][\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[i][\"text\"][0])\n",
        "\n",
        "            # Start token index of the answer in the context\n",
        "            token_start_index = context_start\n",
        "            while token_start_index < len(input_id) and offsets[token_start_index][0] <= start_char:\n",
        "                token_start_index += 1\n",
        "            token_start_index -= 1\n",
        "\n",
        "            # End token index of the answer in the context\n",
        "            token_end_index = context_end\n",
        "            while token_end_index >= 0 and offsets[token_end_index][1] >= end_char:\n",
        "                token_end_index -= 1\n",
        "            token_end_index += 1\n",
        "\n",
        "            # If the tokenized answer does not match the character answer span,\n",
        "            # or if the answer is outside the context, label with the CLS index\n",
        "            if not (token_start_index >= context_start and\n",
        "                    token_end_index <= context_end and\n",
        "                    offsets[token_start_index][0] == start_char and\n",
        "                    offsets[token_end_index][1] == end_char):\n",
        "                start_positions.append(cls_index)\n",
        "                end_positions.append(cls_index)\n",
        "            else:\n",
        "                start_positions.append(token_start_index)\n",
        "                end_positions.append(token_end_index)\n",
        "\n",
        "    tokenized_inputs[\"start_positions\"] = start_positions\n",
        "    tokenized_inputs[\"end_positions\"] = end_positions\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "tokenized = raw.map(preprocess_batch, batched=True, remove_columns=raw[\"train\"].column_names)\n",
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "113d2d69a9d84894b4d8c9484bea0c73",
            "d51dc50982d8447da4d45c2b398097b1",
            "7a597d326f2c491f8cb9ecd4fd041ad5",
            "f6d514e9c82a41fda7b7907e5629b3dd",
            "0f870733fc094da7b83cefd4584bfbc9",
            "03ebe6c333324845ac88d6c6f0c69fd2",
            "9fd44837d3814d82af8245d6c60080d9",
            "37f98b89bd274a858ff19a7c63d7b3ab",
            "8dffa9f2ffb4409db53108ca9c6955f7",
            "4a800b7b532c475d94abb7cf748d36ae",
            "4b94255b9bdf4c1d921e875a42884ee7",
            "93eb08183d804bb3a92caaa64a30430b",
            "d9f28535c4634d879f974646de44094f",
            "874512c9389640a28eb1242e7a4aa814",
            "ad4280f4b6264d0e931ad2f754fb9ec8",
            "35c195ddb818493182155649cf3da620",
            "0ec13d77d7324b168936a2bc702025a3",
            "f2242e7816794528b6923cc352ce4974",
            "69cb568f08664e508d6d8c2519c529d4",
            "164d374fa6c34c9692d2a9410e2a91b3",
            "141b8ed22423450f8091c8834f33404f",
            "fb545fab7ee14908b0ddb5c283391f0b"
          ]
        },
        "id": "cwlYVpLXp_YV",
        "outputId": "fb8d4029-8d18-4829-f225-91d7809fa608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "113d2d69a9d84894b4d8c9484bea0c73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93eb08183d804bb3a92caaa64a30430b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n",
              "        num_rows: 5\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n",
              "        num_rows: 1\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training part\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model_ckpt = \"deepset/roberta-base-squad2\"\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
        "\n",
        "# Metrics (EM/F1) for QA\n",
        "metric = evaluate.load(\"squad_v2\")  # works for SQuAD v2; also fine for v1 if no unanswerables\n",
        "\n",
        "def postprocess_predictions(examples, features, predictions, n_best_size=20, max_answer_length=50):\n",
        "    \"\"\"\n",
        "    Quick post-processing for evaluation. For production, consider HF's official QA post-process utils.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "    start_logits, end_logits = predictions\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = defaultdict(list)\n",
        "    for i, f_id in enumerate(features[\"overflow_to_sample_mapping\"]):\n",
        "        features_per_example[f_id].append(i)\n",
        "\n",
        "    preds = {}\n",
        "    for example_index, example_id in enumerate(examples[\"id\"]):\n",
        "        feature_indices = features_per_example.get(example_index, [])\n",
        "        best_score = -1e9\n",
        "        best_answer = \"\"\n",
        "        context = examples[\"context\"][example_index]\n",
        "\n",
        "        for fi in feature_indices:\n",
        "            starts = start_logits[fi]\n",
        "            ends = end_logits[fi]\n",
        "            start_indexes = np.argsort(starts)[-1:-n_best_size-1:-1]\n",
        "            end_indexes = np.argsort(ends)[-1:-n_best_size-1:-1]\n",
        "            for s in start_indexes:\n",
        "                for e in end_indexes:\n",
        "                    if e < s or (e - s + 1) > max_answer_length:\n",
        "                        continue\n",
        "                    score = starts[s] + ends[e]\n",
        "                    # naive char span mapping with fast tokenizer\n",
        "                    # for a production system, use offset_mapping from tokenizer\n",
        "                    # Here we fallback: output just the top scoring span indexes\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_answer = \"\"  # set later as we didn't compute char offsets here\n",
        "        # Fallback: empty; metrics won't be perfect without proper offsets (see note below)\n",
        "        preds[example_id] = best_answer\n",
        "    return preds\n",
        "\n",
        "# NOTE:\n",
        "# For proper EM/F1 evaluation you should use offset mappings from the tokenizer to extract exact spans.\n",
        "# Keeping training simple here; you can still train and then evaluate qualitatively or add full post-processing later.\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bert-system-design\",\n",
        "    eval_strategy=\"epoch\",   # or \"epoch\"\n",
        "    eval_steps=50,                  # run eval every 50 steps\n",
        "    logging_strategy=\"steps\",       # <– enable per-step logging\n",
        "    logging_steps=10,               # <– print every 10 steps\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",               # avoid WandB popups\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "ZCG82BuiqHFr",
        "outputId": "cebbc8ad-1af3-4886-e2b1-34621f3c4a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2561891385.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.711914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.711914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.711914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=2.3478902180989585, metrics={'train_runtime': 27.907, 'train_samples_per_second': 0.538, 'train_steps_per_second': 0.108, 'total_flos': 3919451351040.0, 'train_loss': 2.3478902180989585, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save and download\n",
        "from google.colab import files\n",
        "model.save_pretrained(\"bert-system-design\")\n",
        "tokenizer.save_pretrained(\"bert-system-design\")\n",
        "!zip -qr bert-system-design.zip bert-system-design\n",
        "files.download(\"bert-system-design.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "g1mfB1ydtv7n",
        "outputId": "ed96739d-16ec-4553-92f9-fd61ffd2b45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93ea9810-4d20-41b2-ab59-efa798c5f0bb\", \"bert-system-design.zip\", 1837183465)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}