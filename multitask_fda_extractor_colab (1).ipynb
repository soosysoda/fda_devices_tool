{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "26fdc3a9",
      "metadata": {
        "id": "26fdc3a9"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -q transformers scikit-learn pandas matplotlib openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d882c95c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d882c95c",
        "outputId": "d20f007c-809b-4500-a610-5fde9980cb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Imports & Config\n",
        "import os, math, random, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# Model / tokenization backbone\n",
        "BACKBONE = \"bert-base-uncased\"\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 8\n",
        "LR = 2e-5\n",
        "EPOCHS = 3\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "LABEL_COLUMNS = [\"hardware\",\"software\",\"ai_models\",\"data_pipelines\",\"user_interface\",\"integrations\"]\n",
        "print(\"Using device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d37f9c2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "d37f9c2c",
        "outputId": "52365ed7-c770-433d-c037-5769c0851611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 641\n",
            "hardware          207\n",
            "software          541\n",
            "ai_models         176\n",
            "data_pipelines    493\n",
            "user_interface    421\n",
            "integrations      393\n",
            "Name: positives_per_head, dtype: int64\n",
            "Sample rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          text_chunk  hardware  software  \\\n",
              "0  CINA-ASPECTS is a standalone computer-aided di...         1         1   \n",
              "1  CINA-ASPECTS is a standalone executable progra...         1         1   \n",
              "2  The score includes which ASPECT regions are id...         1         1   \n",
              "\n",
              "   ai_models  data_pipelines  user_interface  integrations  \n",
              "0          0               1               0             0  \n",
              "1          1               1               1             1  \n",
              "2          1               1               1             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-671aa8b4-68d4-428c-ab65-d2b1f9b5b902\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_chunk</th>\n",
              "      <th>hardware</th>\n",
              "      <th>software</th>\n",
              "      <th>ai_models</th>\n",
              "      <th>data_pipelines</th>\n",
              "      <th>user_interface</th>\n",
              "      <th>integrations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CINA-ASPECTS is a standalone computer-aided di...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CINA-ASPECTS is a standalone executable progra...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The score includes which ASPECT regions are id...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-671aa8b4-68d4-428c-ab65-d2b1f9b5b902')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-671aa8b4-68d4-428c-ab65-d2b1f9b5b902 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-671aa8b4-68d4-428c-ab65-d2b1f9b5b902');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-08abbfa8-8d71-4fde-b548-29fd0db14e27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08abbfa8-8d71-4fde-b548-29fd0db14e27')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-08abbfa8-8d71-4fde-b548-29fd0db14e27 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"text_chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"CINA-ASPECTS is a standalone computer-aided diagnosis (CADx) software that processes non-\\ncontrast head CT (NCCT).\",\n          \"CINA-ASPECTS is a standalone executable program that may be run directly from the command-\\nline or through integration, deployment and use with medical image communications devices. The\\n\\nsoftware does not interface directly with any CT scanner or data collection equipment; instead, the\\nsoftware receives non-contrast head CT (NCCT) scans identified by medical image\\ncommunications devices, processes them using algorithmic methods involving execution of\\nmultiple computational steps to provide an automatic ASPECT score based on the case input file\\nfor the physician.\",\n          \"The score includes which ASPECT regions are identified based on regional imaging features\\nderived from non-contrast computed tomography (NCCT) brain image data and overlaid onto brain\\nscan images. The results are generated based on the Alberta Stroke Program Early CT Score\\n(ASPECTS) guidelines and provided to the clinician for review and verification. At the discretion of\\nthe clinician, the scores may be adjusted based on the clinician\\u00c2\\u0092s judgment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hardware\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"software\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ai_models\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_pipelines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_interface\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"integrations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load dataset\n",
        "CSV_PATH = \"/content/augmented_real_fda_dataset.csv\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH, encoding='latin-1')\n",
        "\n",
        "# Keep only the columns we need\n",
        "keep_cols = [\"text_chunk\"] + LABEL_COLUMNS\n",
        "df = df[keep_cols]\n",
        "\n",
        "# Normalize text\n",
        "df[\"text_chunk\"] = df[\"text_chunk\"].astype(str).fillna(\"\").str.strip()\n",
        "\n",
        "# Convert labels into binary presence/absence per head\n",
        "def to_binary(cell):\n",
        "    if pd.isna(cell):\n",
        "        return 0\n",
        "    s = str(cell).strip()\n",
        "    return 0 if (s == \"\" or s == \"-\" or s.lower() == \"na\") else 1\n",
        "\n",
        "for col in LABEL_COLUMNS:\n",
        "    df[col] = df[col].apply(to_binary).astype(int)\n",
        "\n",
        "# Drop rows with empty text\n",
        "df = df[df[\"text_chunk\"].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "# Quick stats\n",
        "print(\"Rows:\", len(df))\n",
        "print(df[LABEL_COLUMNS].sum().rename(\"positives_per_head\"))\n",
        "print(\"Sample rows:\")\n",
        "display(df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e27ca7e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "a95bb71ccc6f4a469ffeb4ab785e3335",
            "3d441f59b44048e09eb829284ae3a5cc",
            "f810a330a53248a4b919ae0a1f3d45dc",
            "7d09e49926f94fbe83da1be95adc905e",
            "4feb9a3fa0174337945d28c23e7a987f",
            "61f6640de46c4939901d9672dc07e24b",
            "2c1ed3bdddef4188901f035f9894acef",
            "5863862922524e719e5afa1578a461bd",
            "f2b5252e6d7849c4835297d2dd0244b1",
            "fa1c31b4e7a44707b649f19aeff4b2cd",
            "3d07e85f534f4ffea89c653374fad707",
            "245f6bcc2e86476ca2f24008ca49c4ae",
            "99d74ed911b744869d1d394b2fcdd5af",
            "1b163b236b3744cb8617f2037a612ab4",
            "431bbb48bd6d4fc89a450122faa91f0e",
            "568604f8ae7c454e9f365b72682b2009",
            "e99858703aaf4bbfb6ff0eb6a7dd38f8",
            "8b80fed4739c442b814f10b1dfcdf69d",
            "41b9a0cd204f42729d760139001ba8a8",
            "792f7dd3a1244ad89cae15bf94a99b03",
            "0caa142257e548efbaec098340836f24",
            "eba1baba1f8243869d7768a324030183",
            "a262b3723dda4c6cb5b327d9e9a9ac63",
            "12b87ea9ec27472795980aec7950a564",
            "1891c6e1966049a5bbde6fe0293a5f72",
            "f6135398af5b42e2b6f88d587a91ea75",
            "0cf7e2c3c11e4905a19d85fa20f11c21",
            "a51034e9327f4e1eaed4ddb143da857d",
            "d44ae21d4be34acd96189baadc209e86",
            "b3c3fa6067f74a539baf64eab326edbc",
            "e8b55fff48a74b7a8ea570fc4aeaa028",
            "9d98fdd53e684eb0ac555270bc898f6a",
            "58f56c1de3424fd5a2566999478127b1",
            "fd924d5f8b29404dba3e731d072a4f8d",
            "254f0fb1e600448bb4070e2f6cd219ec",
            "6443894f04ff42b2a41702e0e1b3deb3",
            "19a7b6d73369486892ba7b30d3201668",
            "55cee4afa0d047b6acbd5117abac581f",
            "29758474468e4eb49f093e5a4431e44e",
            "5afc17ccd8ed4e439883a9629fd14b75",
            "a0327a9d72fe4f50adc0346150c188f6",
            "383a12487b204a1fb0725f1037e94ced",
            "e536ebba4f8c4ba9b8254c0745a1493f",
            "9daa3cd1d6a94d00a8e971755b7ab52f"
          ]
        },
        "id": "e27ca7e5",
        "outputId": "dd8aa25c-0be4-4885-911e-940c77c08aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a95bb71ccc6f4a469ffeb4ab785e3335"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "245f6bcc2e86476ca2f24008ca49c4ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a262b3723dda4c6cb5b327d9e9a9ac63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd924d5f8b29404dba3e731d072a4f8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 129)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Dataset & DataLoader\n",
        "tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n",
        "\n",
        "class FDADataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=256):\n",
        "        self.texts = df[\"text_chunk\"].tolist()\n",
        "        self.labels = df[LABEL_COLUMNS].values.astype(np.float32)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoded = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in encoded.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# Due to sparsity issues with multi-label stratification,\n",
        "# we will perform a simple random split instead of stratification.\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_ds = FDADataset(train_df, tokenizer, MAX_LEN)\n",
        "test_ds  = FDADataset(test_df, tokenizer, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "len(train_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fa99e811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f6a75ced577d461a8edbb87c7306095b",
            "d9991357b9074eedb903d2d47690c929",
            "686cba47a2204f80bbc87f9e5fd09ddc",
            "0351398bbdbc499c9a923f7d6dc171ea",
            "ab1a9c51d7cd4b898cd7b08ec80127d1",
            "ee7634d4005c445d8d6f0696d9ff5a0b",
            "1bb923e61acc46daba8cbe737df750bd",
            "41434ad810624c6eb9e03c8e3f62d70f",
            "2fd5d9989b6946cba2339323c89e4564",
            "7df208a098c94184a643e1b4c749bd16",
            "1ce1c23384da48daac9b68a7f783ac59"
          ]
        },
        "id": "fa99e811",
        "outputId": "b93e1f9e-3fec-4562-afed-be0a77dd1d76"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a75ced577d461a8edbb87c7306095b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109.486854"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Model: Shared Encoder + Multi-Head Classifier\n",
        "class MultiHeadExtractor(nn.Module):\n",
        "    def __init__(self, backbone=\"bert-base-uncased\", num_heads=6):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(backbone)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "        # one linear head per label (binary)\n",
        "        self.heads = nn.ModuleList([nn.Linear(hidden_size, 1) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "        logits = torch.cat([head(pooled) for head in self.heads], dim=1)  # shape: (B, num_heads)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.BCEWithLogitsLoss()\n",
        "            loss = loss_fn(logits, labels)\n",
        "        return {\"logits\": logits, \"loss\": loss}\n",
        "\n",
        "model = MultiHeadExtractor(backbone=BACKBONE, num_heads=len(LABEL_COLUMNS)).to(DEVICE)\n",
        "sum(p.numel() for p in model.parameters())/1e6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d6d43dcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6d43dcb",
        "outputId": "5a8fb0d8-f956-4766-b7b5-986cae1be1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | train_loss=0.5324 | micro P/R/F1 = {'precision': 0.822680412371134, 'recall': 0.8807947019867549, 'f1': 0.8507462686567164}\n",
            "Per-head metrics:\n",
            "  - hardware: P=0.828 R=0.571 F1=0.676 AUC=0.880\n",
            "  - software: P=0.836 R=1.000 F1=0.911 AUC=0.957\n",
            "  - ai_models: P=1.000 R=0.258 F1=0.410 AUC=0.910\n",
            "  - data_pipelines: P=0.867 R=1.000 F1=0.929 AUC=0.931\n",
            "  - user_interface: P=0.857 R=0.876 F1=0.867 AUC=0.837\n",
            "  - integrations: P=0.716 R=0.975 F1=0.825 AUC=0.852\n",
            "Epoch 2 | train_loss=0.3300 | micro P/R/F1 = {'precision': 0.899581589958159, 'recall': 0.9492273730684326, 'f1': 0.9237379162191193}\n",
            "Per-head metrics:\n",
            "  - hardware: P=0.914 R=0.762 F1=0.831 AUC=0.953\n",
            "  - software: P=0.907 R=1.000 F1=0.951 AUC=0.980\n",
            "  - ai_models: P=0.897 R=0.839 F1=0.867 AUC=0.968\n",
            "  - data_pipelines: P=0.936 R=0.990 F1=0.963 AUC=0.942\n",
            "  - user_interface: P=0.913 R=0.944 F1=0.928 AUC=0.948\n",
            "  - integrations: P=0.830 R=0.975 F1=0.897 AUC=0.919\n",
            "Epoch 3 | train_loss=0.1988 | micro P/R/F1 = {'precision': 0.9458874458874459, 'recall': 0.9646799116997793, 'f1': 0.9551912568306011}\n",
            "Per-head metrics:\n",
            "  - hardware: P=0.950 R=0.905 F1=0.927 AUC=0.960\n",
            "  - software: P=0.946 R=0.991 F1=0.968 AUC=0.984\n",
            "  - ai_models: P=0.966 R=0.903 F1=0.933 AUC=0.979\n",
            "  - data_pipelines: P=0.971 R=0.981 F1=0.976 AUC=0.961\n",
            "  - user_interface: P=0.935 R=0.966 F1=0.950 AUC=0.946\n",
            "  - integrations: P=0.917 R=0.963 F1=0.939 AUC=0.965\n",
            "Best micro-F1: 0.9551912568306011\n"
          ]
        }
      ],
      "source": [
        "#Train & Evaluate\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def evaluate(model, loader, threshold=0.5):\n",
        "    model.eval()\n",
        "    all_logits, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            labels = batch[\"labels\"].cpu().numpy()\n",
        "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = out[\"logits\"].cpu().numpy()\n",
        "            all_logits.append(logits)\n",
        "            all_labels.append(labels)\n",
        "    all_logits = np.vstack(all_logits)\n",
        "    all_labels = np.vstack(all_labels)\n",
        "    probs = sigmoid(all_logits)\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    # micro-average metrics\n",
        "    p_micro, r_micro, f_micro, _ = precision_recall_fscore_support(all_labels, preds, average=\"micro\", zero_division=0)\n",
        "    # per-head metrics\n",
        "    head_metrics = {}\n",
        "    for i, head in enumerate(LABEL_COLUMNS):\n",
        "        p, r, f, _ = precision_recall_fscore_support(all_labels[:, i], preds[:, i], average=\"binary\", zero_division=0)\n",
        "        try:\n",
        "            auc = roc_auc_score(all_labels[:, i], probs[:, i])\n",
        "        except Exception:\n",
        "            auc = float(\"nan\")\n",
        "        head_metrics[head] = {\"precision\": p, \"recall\": r, \"f1\": f, \"auc\": auc}\n",
        "    return {\"micro\": {\"precision\": p_micro, \"recall\": r_micro, \"f1\": f_micro}, \"per_head\": head_metrics}\n",
        "\n",
        "best_f1 = 0.0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "        out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = out[\"loss\"]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    metrics = evaluate(model, test_loader, threshold=0.5)\n",
        "    print(f\"Epoch {epoch} | train_loss={avg_loss:.4f} | micro P/R/F1 = {metrics['micro']}\")\n",
        "    print(\"Per-head metrics:\")\n",
        "    for k,v in metrics[\"per_head\"].items():\n",
        "        print(f\"  - {k}: P={v['precision']:.3f} R={v['recall']:.3f} F1={v['f1']:.3f} AUC={v['auc']:.3f}\")\n",
        "    best_f1 = max(best_f1, metrics[\"micro\"][\"f1\"])\n",
        "print(\"Best micro-F1:\", best_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f9ac9dda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ac9dda",
        "outputId": "5654f97e-2776-4ef6-d127-b83c8fd60316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: {\n",
            "  \"hardware\": 0.32658544182777405,\n",
            "  \"software\": 0.9732354283332825,\n",
            "  \"ai_models\": 0.6761454343795776,\n",
            "  \"data_pipelines\": 0.9021890759468079,\n",
            "  \"user_interface\": 0.04732263460755348,\n",
            "  \"integrations\": 0.9350360035896301\n",
            "}\n",
            "Predicted heads: ['software', 'ai_models', 'data_pipelines', 'integrations']\n"
          ]
        }
      ],
      "source": [
        "# Inference on custom text\n",
        "def predict_heads(text, threshold=0.5):\n",
        "    model.eval()\n",
        "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        # Only pass input_ids and attention_mask to the model's forward method\n",
        "        out = model(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"])\n",
        "        probs = torch.sigmoid(out[\"logits\"]).cpu().numpy()[0]\n",
        "    result = {head: float(probs[i]) for i, head in enumerate(LABEL_COLUMNS)}\n",
        "    preds = [head for head, p in result.items() if p >= threshold]\n",
        "    return result, preds\n",
        "\n",
        "sample_text = \"The software runs on a Linux server and uses deep learning to process DICOM CT images, then exports DICOM to PACS.\"\n",
        "scores, heads = predict_heads(sample_text, threshold=0.5)\n",
        "print(\"Scores:\", json.dumps(scores, indent=2))\n",
        "print(\"Predicted heads:\", heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343d2fa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "343d2fa9",
        "outputId": "8c997459-8ee3-4960-efcf-9c616cb2a26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /content/multitask_fda_extractor\n"
          ]
        }
      ],
      "source": [
        "# Save model & tokenizer\n",
        "SAVE_DIR = \"/content/multitask_fda_extractor\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"pytorch_model.bin\"))\n",
        "# Save label mapping & backbone\n",
        "with open(os.path.join(SAVE_DIR, \"labels.json\"), \"w\") as f:\n",
        "    json.dump({\"labels\": LABEL_COLUMNS, \"backbone\": BACKBONE, \"max_len\": MAX_LEN}, f, indent=2)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "print(\"Saved to:\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/multitask_fda_extractor.zip /content/multitask_fda_extractor\n",
        "\n",
        "# Provide a download link for the zip file\n",
        "from google.colab import files\n",
        "files.download('/content/multitask_fda_extractor.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "08skZ-hwJtun",
        "outputId": "52543a03-8075-49b8-86f7-54556e810376"
      },
      "id": "08skZ-hwJtun",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/multitask_fda_extractor/ (stored 0%)\n",
            "  adding: content/multitask_fda_extractor/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/multitask_fda_extractor/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/multitask_fda_extractor/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/multitask_fda_extractor/labels.json (deflated 31%)\n",
            "  adding: content/multitask_fda_extractor/tokenizer.json (deflated 71%)\n",
            "  adding: content/multitask_fda_extractor/vocab.txt (deflated 53%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d2c2582-80c6-42d6-ac9e-9909f6e5baef\", \"multitask_fda_extractor.zip\", 405595680)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}